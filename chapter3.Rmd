***

# Part 3. Regression, logistic regression

***

In the last two parts I didn't reflect on my learning. The main reason for this is that I didn't read the instructions carefully enough and didn't know I had to do it. This rash style of working can also be seen in the quality of the exercises. All in all, I hope I learned lesson here and be more precise in the future exercises. That said, let's continue to the logistic regression!

### Logistic regression

```{r}
alc <- read.csv("./data/alc_data.csv", sep = ",")
library(dplyr)
library(GGally)
library(ggplot2)
str(alc)
```

The data is from 382 students in Portugal or Spain, judging from the names of the schools. It consists of 35 variables. There's social variables such as gender, age and parents education. Then there's variables related to school, such as study time and grade points from two different courses, math and portugese. Finally there's a bunch of variables that deals with personal life of students. These include variables like relationship with family, does one have a romantic partner and so on.

Students answered two questions regarding their alcohol use. First one is their alcohol use in working days and the another one is alcohol use in weekends. Both are on Likert scale from very low (1) to very high (5). Student was considered a high user if the mean of these two variables were more than 2. I'm interested in what leads to high alcohol use. The hypotheses are as follows:

* H1: Male gender is associated with higher probability to be high user
* H2: Better relationships with family decreases the probability of high use
* H3: Going out with friends increases the probability to be high user
* H4: Parents living apart predispose to high use

```{r}
variables <- c("high_use", "sex", "famrel", "goout", "Pstatus")
alc_data <- select(alc, one_of(variables))
```

Let's examine the relationship of gender and high use first. In the following plot we can see that boys are more likely to be high users.

```{r}
ggplot(alc_data, aes(high_use, color = sex, fill = sex)) + geom_bar(aes(y = ..prop.., group = 1)) + facet_wrap(~sex)
```

```{r}
ggplot(alc_data, aes(high_use, famrel)) + geom_boxplot()
```

In the plot above we can see that students who aren't classified as high users has better relationships with family. In the next plot there's a clear trend which indicates that students who go out with friends are prone to be high user.

```{r}
ggplot(alc_data, aes(high_use, goout)) + geom_boxplot()
```

Let's check the last hypothesis regarding parents' living arrangements. The table below shows that the percentages are almost evenly split ant therefore there is no effect whatsoever.

```{r}
table <- table(alc_data$Pstatus, alc_data$high_use)
prop.table(table, 1)
```
Based on this brief examination three out of four hypotheses seem to be correct. However, these are just preliminary observations. Let's make logistic regression model and see whether the hypotheses stand!

```{r}
m1 <- glm(high_use ~ sex + famrel + goout + Pstatus, data = alc_data, family = "binomial")
summary(m1)

OR <- coef(m1) %>% exp
CI <- confint(m1) %>% exp
cbind(OR, CI)
```
The results indicate that the previous interpretation was correct. The same three hypotheses seem to hold true. Males are 2.5 times more likely to belong to high users. Going out with friends also increases the probability to be a high user. For every one point increase in the outgoing variable, the probality of being a high user more than doubles! On the other hand, good relations with family seems to protect against being a high user. Probability for being a high user drops one thirds for every one point increase in relationship variable. Parents' living arrangements does not have an effect on being a high user.

```{r}
m2 <- glm(high_use ~ sex + famrel + goout, data = alc_data, family = "binomial")
probabilities <- predict(m2, type = "response")
alc_data <- mutate(alc_data, probability = probabilities)
alc_data <- mutate(alc_data, prediction = probability > 0.5)
table(high_use = alc_data$high_use, prediction = alc_data$prediction)
```






6. Using the variables which, according to your logistic regression model, had a statistical relationship with high/low alcohol consumption, explore the predictive power of you model. Provide a 2x2 cross tabulation of predictions versus the actual values and optionally display a graphic visualizing both the actual values and the predictions. Compute the total proportion of inaccurately classified individuals (= the training error) and comment on all the results. Compare the performance of the model with performance achieved by some simple guessing strategy. (0-3 points)

7. Bonus: Perform 10-fold cross-validation on your model. Does your model have better test set performance (smaller prediction error using 10-fold cross-validation) compared to the model introduced in DataCamp (which had about 0.26 error). Could you find such a model? (0-2 points to compensate any loss of points from the above exercises)

8. Super-Bonus: Perform cross-validation to compare the performance of different logistic regression models (= different sets of predictors). Start with a very high number of predictors and explore the changes in the training and testing errors as you move to models with less predictors. Draw a graph displaying the trends of both training and testing errors by the number of predictors in the model. (0-4 points to compensate any loss of points from the above exercises)