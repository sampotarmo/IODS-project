***

# Part 3. Regression, logistic regression

***

In the last two parts I didn't reflect on my learning. The main reason for this is that I didn't read the instructions carefully enough and didn't know I had to do it. This rash style of working can also be seen in the quality of the exercises. All in all, I hope I learned lesson here and be more precise in the future exercises. That said, let's continue to the logistic regression!

### Logistic regression

```{r}
alc <- read.csv("./data/alc_data.csv", sep = ",")
library(dplyr)
library(GGally)
library(ggplot2)
str(alc)
```

The data is from 382 students in Portugal or Spain, judging from the names of the schools. It consists of 35 variables. There's social variables such as gender, age and parents education. Then there's variables related to school, such as study time and grade points from two different courses, math and portugese. Finally there's a bunch of variables that deals with personal life of students. These include variables like relationship with family, does one have a romantic partner and so on.

Students answered two questions regarding their alcohol use. First one is their alcohol use in working days and the another one is alcohol use in weekends. Both are on Likert scale from very low (1) to very high (5). Student was considered a high user if the mean of these two variables were more than 2. I'm interested in what leads to high alcohol use. The hypotheses are as follows:

* H1: Male gender is associated with higher probability to be high user
* H2: Better relationships with family decreases the probability of high use
* H3: Going out with friends increases the probability to be high user
* H4: Parents living apart predispose to high use

```{r}
variables <- c("high_use", "sex", "famrel", "goout", "Pstatus")
alc_data <- select(alc, one_of(variables))
```

Let's examine the relationship of gender and high use first. In the following plot we can see that boys are more likely to be high users.

```{r}
ggplot(alc_data, aes(high_use, color = sex, fill = sex)) + geom_bar(aes(y = ..prop.., group = 1)) + facet_wrap(~sex)
```

```{r}
ggplot(alc_data, aes(high_use, famrel)) + geom_boxplot()
```

In the plot above we can see that students who aren't classified as high users has better relationships with family. In the next plot there's a clear trend which indicates that students who go out with friends are prone to be high user.

```{r}
ggplot(alc_data, aes(high_use, goout)) + geom_boxplot()
```

Let's check the last hypothesis regarding parents' living arrangements. The table below shows that the percentages are almost evenly split ant therefore there is no effect whatsoever.

```{r}
table <- table(alc_data$Pstatus, alc_data$high_use)
prop.table(table, 1)
```
Based on this brief examination three out of four hypotheses seem to be correct. However, these are just preliminary observations. Let's make logistic regression model and see whether the hypotheses stand!

```{r}
m1 <- glm(high_use ~ sex + famrel + goout + Pstatus, data = alc_data, family = "binomial")
summary(m1)

OR <- coef(m1) %>% exp
CI <- confint(m1) %>% exp
cbind(OR, CI)
```
The results indicate that the previous interpretation was correct. The same three hypotheses seem to hold true. Males are 2.5 times more likely to belong to high users. Going out with friends also increases the probability to be a high user. For every one point increase in the outgoing variable, the probality of being a high user more than doubles! On the other hand, good relations with family seems to protect against being a high user. Probability for being a high user drops one thirds for every one point increase in relationship variable. Parents' living arrangements does not have an effect on being a high user.

```{r}
m2 <- glm(high_use ~ sex + famrel + goout, data = alc_data, family = "binomial")
probabilities <- predict(m2, type = "response")
alc_data <- mutate(alc_data, probability = probabilities)
alc_data <- mutate(alc_data, prediction = probability > 0.5)
table(high_use = alc_data$high_use, prediction = alc_data$prediction)
ggplot(alc_data, aes(probability, high_use, col = prediction)) + geom_point()
```

From the table above we can calculate the total proportion of right and wrong predictions. Total proportion on right answers (p) is 78.8 percent. Hence, the total wrong predictions are 1-p = 21.2 percent. The plot shows the thing but atleast for me it's more difficult to interpret.

```{r}
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}
loss_func(class = alc_data$high_use, prob = alc_data$probability)
```

The number above represents the average *wrong* predictions. By guessing the probability of right or wrong answer should be around 0.5, so we can conclude that the model is better than a sheer guess.

The next chuck performs a 10-fold cross validation. What it does, tt divides the data in ten chunks of data, uses 9 parts of them to "train" the model and tests the model with the remaining part of the data. It repeats this process nine more times changing the test chunk.

```{r}
library(boot)
cv <- cv.glm(data = alc_data, cost = loss_func, glmfit = m2, K = 10)
cv$delta[1]
```
If I got it right, the number above is the *mean prediction error* for the ten sets of validation. It seems to work a little worse than the original model, but somewhat better than the model in Datacamp.