***

# Part 3. Regression, logistic regression

***

In the last two parts I didn't reflect on my learning. The main reason for this is that I didn't read the instructions carefully enough and didn't know I had to do it. This rash style of working can also be seen in the quality of the exercises. All in all, I hope I learned lesson here and be more precise in the future exercises. That said, let's continue to the logistic regression!

### Logistic regression

```{r}
alc <- read.csv("./data/alc_data.csv", sep = ",")
library(dplyr)
library(GGally)
library(ggplot2)
str(alc)
```

The data is from 382 students in Portugal or Spain, judging from the names of the schools. It consists of 35 variables. There's social variables such as gender, age and parents education. Then there's variables related to school, such as study time and grade points from two different courses, math and portugese. Finally there's a bunch of variables that deals with personal life of students. These include variables like relationship with family, does one have a romantic partner and so on.

Students answered two questions regarding their alcohol use. First one is their alcohol use in working days and the another one is alcohol use in weekends. Both are on Likert scale from very low (1) to very high (5). Student was considered a high user if the mean of these two variables were more than 2. I'm interested in what leads to high alcohol use. The hypotheses are as follows:

* H1: Male gender is associated with higher probability to be high user
* H2: Better relationships with family decreases the probability of high use
* H3: Going out with friends increases the probability to be high user
* H4: Parents living apart predispose to high use

```{r}
variables <- c("high_use", "sex", "famrel", "goout", "Pstatus")
alc_data <- select(alc, one_of(variables))
```

Let's examine the relationship of gender and high use first. In the following plot we can see that boys are more likely to be high users.
```{r}
ggplot(alc_data, aes(high_use, color = sex, fill = sex)) + geom_bar(aes(y = ..prop.., group = 1)) + facet_wrap(~sex)
```

4. Numerically and graphically explore the distributions of your chosen variables and their relationships with alcohol consumption (use for example cross-tabulations, bar plots and box plots). Comment on your findings and compare the results of your exploration to your previously stated hypotheses. 

5. Use logistic regression to statistically explore the relationship between your chosen variables and the binary high/low alcohol consumption variable as the target variable. Present and interpret a summary of the fitted model. Present and interpret the coefficients of the model as odds ratios and provide confidence intervals for them. Interpret the results and compare them to your previously stated hypothesis. Hint: If your model includes factor variables see for example the first answer of this stackexchange thread on how R treats and how you should interpret these variables in the model output (or use some other resource to study this). (0-5 points)

6. Using the variables which, according to your logistic regression model, had a statistical relationship with high/low alcohol consumption, explore the predictive power of you model. Provide a 2x2 cross tabulation of predictions versus the actual values and optionally display a graphic visualizing both the actual values and the predictions. Compute the total proportion of inaccurately classified individuals (= the training error) and comment on all the results. Compare the performance of the model with performance achieved by some simple guessing strategy. (0-3 points)

7. Bonus: Perform 10-fold cross-validation on your model. Does your model have better test set performance (smaller prediction error using 10-fold cross-validation) compared to the model introduced in DataCamp (which had about 0.26 error). Could you find such a model? (0-2 points to compensate any loss of points from the above exercises)

8. Super-Bonus: Perform cross-validation to compare the performance of different logistic regression models (= different sets of predictors). Start with a very high number of predictors and explore the changes in the training and testing errors as you move to models with less predictors. Draw a graph displaying the trends of both training and testing errors by the number of predictors in the model. (0-4 points to compensate any loss of points from the above exercises)