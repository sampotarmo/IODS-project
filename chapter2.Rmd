# Part 2. The adventure continues by regression!

```{r}
learning <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt", sep = ",", header = T)
str(learning)
```

The data comes from a survey that was carried out in Finland and has something to do with learning. The data seems to be identical with the data we made in data wrangling exercise. This, too,  contains 166 observations and seven variables, two of which are background variables age and gender. Points is points from an exam. What kind of an exam and where, the legend doesn't tell. Variable "attitude" is respondents attitude towards statistics. I found no key how to interpret the scale, but it varies from 1.4 to 5. The last three are sum variables that measures a latent features deep, surface and strategic learning.

```{r, echo=FALSE}
library(GGally)
library(ggplot2)
ggpairs(learning, mapping = aes(col = gender, alpha = 0.5), lower = list(combo = wrap("facethist", bins = 20)))
```

The data is summarised in the picture above. At first glance there seems to **a lot** going on. Let's tackle the descriptive statistics first (`describe` from package `Hmisc`). There's 110 women and 56 men. The mean age of respondents is 25.5 years, men being a little older than women. Men's attitude towards statistics is visibly more positive than women's.

More interesting stuff is shown in correlation matrices. From there we can gather that positive attitude towards statistics is related to better points in exam and the effect is quite similar between genders. Surface learning and deep learning have quite a strong negative correlation within men, but almost none within women. It seems that surface learning is off from deep learning and vice versa.

### Regression

I thought that the points _should_ depend on learning and attitude. According to this, the first model I fitted included attitude, deep learning and strategic learning as independent variables. From the legend provided by 
Kimmo, I gathered that deep and strategic learning are better than surface learning in some ways. They focus more on learning than passing the class.

```{r}
mod1 <- lm(points ~ attitude + deep + stra, data = learning)
summary(mod1)
```

The statistical test of intercept has following hypotheses:

H0: intercept is 0 \
Ha: intercept is not 0

Usually the intercept is *not* the subject of interest. It simply tells the value of the depending variable when all the independent variables are zero (disregarding the measurement error). What's more interesting are the regression estimates for the independent variables. The hypotheses concerning the regression slope estimates for each variable are:

H0: regression slope is 0 (when all other independent variables are controlled) \
Ha: regression slope is not 0 (when all other independent variables are controlled)

The p value tells us the propability of getting equal or more extreme results *if* the null hypothesis is true. So, in this case we can conclude that only attitude has a regression slope differing from zero. As instructed, we now remove the two non-significant variables from the model.

```{r}
mod3 <- lm(points ~ attitude, data = learning)
summary(mod3)
```

Attitude towards statistics seems to have positive effect on points. At this point, I can only assume the exam has something to do with statistics. The interpretation for the regression slope is as follows:

When attitude increase by one, exam points increase by approximately 3.5

From the table above we can see that the R-squared for this model is 0.1856. This means the attitude "explains" almost 19 percent of the variance of points. In other words, other factors explain more than four fifths of the variance of the points.

### Diagnostics

Now, let's turn to diagnostics of the model. Does the model meet the assumptions of linear regression? Does it fit the data?

There are many assumptions in linear regression. One of these is the *homoscedasticity* or constant variance. This means that the error has same variance regardless of the values of the independent variables. This can be checked using scatter plot of residuals and predicted values:

```{r}
plot(mod3, which = c(1))
```

What we *want* to see in the plot is that the errors aren't "fanning out". In the plot above, we can see that this holds true, excluding the few numbered errors at the bottom.

The second assumption is the normal distribution of errors. This can be checked with a QQ-plot:

```{r}
plot(mod3, which = c(2))
```

Here we want to see if the points set on the straight line which would indicate the normal distribution of the errors. In this case, they set quite nicely on the line. One should notice that inspection is purely visual. Hence, the decision is rather subjective.

The last diagnostics is to see if any of the observations have too much leverage power. This means that appropriately placed observation(s) could "pull in" the regression slope. In the plot below we can see there's only few observations that can be considered as potential outliers with too much leverage. Here too, the decision is based on visual interpretation and to my eye these few observations aren't alarming.

```{r}
plot(mod3, which = c(5))
```

Overall the model seems to fit quite nicely and doesn't violate the assumptions. We can conclude (setting the causality aside) that positive attitude towards statistics leads to better performance in exams.